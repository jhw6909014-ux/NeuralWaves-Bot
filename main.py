import os
import random
import asyncio
import requests
import google.generativeai as genai
import edge_tts
from gtts import gTTS
from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip, ColorClip
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError

# --- è¨­å®šå€ ---
GEMINI_KEY = os.environ["GEMINI_API_KEY"]
YT_CLIENT_ID = os.environ["YT_CLIENT_ID"]
YT_CLIENT_SECRET = os.environ["YT_CLIENT_SECRET"]
YT_REFRESH_TOKEN = os.environ["YT_REFRESH_TOKEN"]

# --- 1. ä¸‹è¼‰èƒŒæ™¯å½±ç‰‡ ---
def get_background_video():
    print("ğŸ“¥ æ­£åœ¨æº–å‚™èƒŒæ™¯å½±ç‰‡...")
    urls = [
        "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/classroom.mp4",
        "https://videos.pexels.com/video-files/855018/855018-hd_1920_1080_30fps.mp4",
        "https://upload.wikimedia.org/wikipedia/commons/transcoded/c/c5/Time_lapse_of_clouds_over_mountains.webm/Time_lapse_of_clouds_over_mountains.webm.720p.vp9.webm"
    ]
    headers = {"User-Agent": "Mozilla/5.0"}

    for url in urls:
        try:
            print(f"å˜—è©¦ä¸‹è¼‰: {url[:40]}...")
            r = requests.get(url, stream=True, headers=headers, timeout=20)
            if r.status_code == 200:
                filename = "bg.mp4"
                with open(filename, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=1024*1024):
                        f.write(chunk)
                if os.path.getsize(filename) > 10000:
                    print("âœ… ä¸‹è¼‰æˆåŠŸï¼")
                    return filename, False
        except:
            continue
    
    print("âš ï¸ ä¸‹è¼‰å¤±æ•—ï¼Œä½¿ç”¨ç´”è‰²èƒŒæ™¯")
    return "color_bg", True

# --- 2. AI ç”Ÿæˆæ–‡æ¡ˆ (å„ªå…ˆç”¨ Pro ç‰ˆ) ---
def get_ai_script():
    print("ğŸ§  æ­£åœ¨ç”Ÿæˆ AI æ–‡æ¡ˆ...")
    genai.configure(api_key=GEMINI_KEY)
    
    # æ”¹å› gemini-pro é¿å… 404 éŒ¯èª¤
    try:
        model = genai.GenerativeModel('gemini-pro')
        response = model.generate_content("çµ¦æˆ‘ä¸€å€‹é—œæ–¼'å†·çŸ¥è­˜'çš„çŸ­å½±éŸ³è…³æœ¬ï¼Œå…©è¡Œï¼šæ¨™é¡Œèˆ‡å…§æ–‡ã€‚")
    except:
        try:
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content("çµ¦æˆ‘ä¸€å€‹é—œæ–¼'å†·çŸ¥è­˜'çš„çŸ­å½±éŸ³è…³æœ¬ï¼Œå…©è¡Œï¼šæ¨™é¡Œèˆ‡å…§æ–‡ã€‚")
        except:
            return "æ¯æ—¥çŸ¥è­˜", "ä»Šå¤©ä¹Ÿè¦åŠ æ²¹å–”ï¼å …æŒå°±æ˜¯å‹åˆ©ã€‚"

    try:
        text = response.text.strip().split('\n')
        text = [line for line in text if line.strip()]
        if text: return text[0], "".join(text[1:])
    except:
        pass
        
    return "ç³»çµ±æ¸¬è©¦", "è‡ªå‹•åŒ–æ¸¬è©¦å½±ç‰‡ç”ŸæˆæˆåŠŸã€‚"

# --- 3. è½‰èªéŸ³ ---
async def make_voice(text):
    print("ğŸ—£ï¸ è½‰èªéŸ³ä¸­...")
    output = "voice.mp3"
    try:
        communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
        await communicate.save(output)
        if os.path.exists(output) and os.path.getsize(output) > 0:
            return output
    except:
        pass
    
    # å‚™ç”¨
    try:
        tts = gTTS(text=text, lang='zh-tw')
        tts.save(output)
        return output
    except:
        return None

# --- 4. åˆæˆå½±ç‰‡ ---
def make_video(bg_source, is_color_bg, voice_path):
    print("ğŸ¬ æ­£åœ¨åˆæˆ...")
    audio = None
    duration = 10.0
    if voice_path and os.path.exists(voice_path):
        audio = AudioFileClip(voice_path)
        duration = audio.duration + 1.0

    if is_color_bg:
        clip = ColorClip(size=(1080, 1920), color=(20, 30, 80), duration=duration)
    else:
        try:
            clip = VideoFileClip(bg_source)
            w, h = clip.size
            if w/h > 9/16:
                new_w = h * (9/16)
                clip = clip.crop(x1=w/2 - new_w/2, width=new_w, height=h)
            clip = clip.loop(duration=duration)
        except:
            clip = ColorClip(size=(1080, 1920), color=(50, 50, 50), duration=duration)

    if audio: clip = clip.set_audio(audio)
    
    output = "final_output.mp4"
    clip.write_videofile(output, fps=24, codec="libx264", audio_codec="aac", threads=4, logger=None)
    return output

# --- 5. ä¸Šå‚³ (åŒ…å«é¡åº¦æ»¿çš„è™•ç†) ---
def upload_youtube(video_path, title, description):
    print(f"ğŸš€ æº–å‚™ä¸Šå‚³: {title}")
    creds = Credentials(None, refresh_token=YT_REFRESH_TOKEN, token_uri="https://oauth2.googleapis.com/token", client_id=YT_CLIENT_ID, client_secret=YT_CLIENT_SECRET)
    youtube = build("youtube", "v3", credentials=creds)
    
    body = {
        "snippet": {"title": title[:90], "description": description + "\n\n#Shorts #AI", "categoryId": "22"},
        "status": {"privacyStatus": "public", "selfDeclaredMadeForKids": False}
    }
    
    media = MediaFileUpload(video_path, chunksize=1024*1024, resumable=True)
    
    try:
        request = youtube.videos().insert(part="snippet,status", body=body, media_body=media)
        response = None
        while response is None:
            status, response = request.next_chunk()
            if status: print(f"é€²åº¦: {int(status.progress() * 100)}%")
        print("ğŸ‰ ä¸Šå‚³æˆåŠŸï¼")
        
    except HttpError as e:
        if "uploadLimitExceeded" in str(e):
            print("âš ï¸ è­¦å‘Šï¼šä»Šæ—¥ YouTube ä¸Šå‚³é¡åº¦å·²æ»¿ (æ¯æ—¥é™ç´„ 6 æ”¯)ã€‚")
            print("ğŸ’¡ è§£æ±ºæ–¹æ¡ˆï¼šå½±ç‰‡å·²ç”Ÿæˆï¼Œè«‹æ˜å¤©å†è©¦ï¼Œæˆ–æ‰‹å‹•ä¸‹è¼‰ Artifact ä¸Šå‚³ã€‚")
            # é€™è£¡ä¸æ‹‹å‡ºéŒ¯èª¤ï¼Œè®“ Action é¡¯ç¤ºç¶ è‰²æˆåŠŸ
        else:
            print(f"âŒ ä¸Šå‚³ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
            raise e

if __name__ == "__main__":
    try:
        bg_file, is_color = get_background_video()
        title, text = get_ai_script()
        voice_file = asyncio.run(make_voice(text))
        final_video = make_video(bg_file, is_color, voice_file)
        upload_youtube(final_video, title, text)
    except Exception as e:
        print(f"âŒ æµç¨‹éŒ¯èª¤: {e}")
